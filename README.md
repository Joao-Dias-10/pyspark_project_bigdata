# ğŸš€ PySpark Big Data Pipeline

Projeto estruturado em PySpark, com foco em boas prÃ¡ticas, orientaÃ§Ã£o a objetos e escalabilidade para tratamento de grandes volumes de dados. A pipeline inclui carregamento, transformaÃ§Ã£o, limpeza, inserÃ§Ãµes otimizadas em bancos relacionais como PostgreSQL e testes unitÃ¡rios.

---

### ğŸ¯ Objetivo do CÃ³digo

Automatizar uma pipeline de ingestÃ£o, processamento e carregamento de dados, capaz de tratar e inserir **mais de 3.9 milhÃµes de registros** com eficiÃªncia, estabilidade e organizaÃ§Ã£o.

Essa soluÃ§Ã£o foi construÃ­da com foco em **boas prÃ¡ticas de engenharia de dados**, utilizando:

* `PySpark` para **processamento distribuÃ­do eficiente**
* `.parquet` como formato de **armazenamento colunar compacto**
* `SQLAlchemy` para **modelagem e criaÃ§Ã£o de tabelas**
* `PostgreSQL` como **destino relacional confiÃ¡vel**
* EstruturaÃ§Ã£o do cÃ³digo em **POO** e mÃ³dulos reutilizÃ¡veis para garantir **manutenibilidade, clareza e escalabilidade**
* `pytest` utilizado para **testes unitÃ¡rios**, garantindo a **confiabilidade das transformaÃ§Ãµes e manutenÃ§Ã£o**

O pipeline automatiza todo o fluxo: baixa o dado bruto, trata e transforma os registros, salva de forma otimizada e insere no banco com escrita em lote â€” tudo controlado por logs e encerramento adequado dos recursos.

---

## âš™ï¸ Tecnologias utilizadas

* Python 3.10+
* PySpark
* PostgreSQL
* Pytest (para testes unitÃ¡rios)
* SQLAlchemy (para modelagem ORM)
* notebooks (para testes e verificaÃ§Ãµes rÃ¡pidas)
* Dotenv (para gerenciamento de variÃ¡veis)
* Logging (para rastreamento de execuÃ§Ã£o)

---

## ğŸ§± Estrutura do projeto

```
â”œâ”€â”€ config/           # Arquivos de configuraÃ§Ã£o (.yaml, .env, etc.)
â”œâ”€â”€ data/             # Dados brutos e processados
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ logs/             # Logs de execuÃ§Ã£o
â”œâ”€â”€ notebooks/        # Cadernos Jupyter para testes manuais e EDA
â”œâ”€â”€ src/              # CÃ³digo-fonte principal
â”‚   â”œâ”€â”€ automation/   # Scripts de automaÃ§Ã£o 
â”‚   â”œâ”€â”€ db/           # LÃ³gica de banco de dados
â”‚   â”‚   â”œâ”€â”€ init_db.py
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â””â”€â”€ queries.py
â”‚   â”œâ”€â”€ preprocessing/ # PrÃ©-processamento e transformaÃ§Ã£o de dados
â”‚   â””â”€â”€ utils/        # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ tests/            # Testes unitÃ¡rios e de integraÃ§Ã£o
â”œâ”€â”€ .gitignore        # PadrÃµes de arquivos ignorados pelo Git
â”œâ”€â”€ main.py           # Ponto de entrada do projeto
â”œâ”€â”€ requirements.txt
```

---

### â–¶ï¸ Rodando o pipeline

```bash
python main.py
```

---

